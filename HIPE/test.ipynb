{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5da03c",
   "metadata": {},
   "source": [
    "# HIPE-2026 Peopleâ€“Place Context (Baseline)\n",
    "This notebook builds a clean baseline for predicting the two labels per (person, location) pair: `at` and `isAt`.\n",
    "\n",
    "**What you can do here**\n",
    "- Load HIPE sandbox train/dev JSONL files\n",
    "- Build pair-level training examples\n",
    "- Fine-tune a transformer encoder (XLM-R) with two classification heads\n",
    "- Evaluate on dev + export predictions in HIPE JSONL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3755f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "torch: 2.9.0+cu126\n",
      "transformers: 4.57.3\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "# If needed, install dependencies.\n",
    "# (In hosted GPU notebooks, torch is often preinstalled.)\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def _pip_install(pkgs):\n",
    "    cmd = [sys.executable, '-m', 'pip', 'install', '-q'] + list(pkgs)\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# Core ML deps\n",
    "try:\n",
    "    import torch  # noqa: F401\n",
    "except Exception:\n",
    "    _pip_install(['torch'])\n",
    "\n",
    "try:\n",
    "    import transformers  # noqa: F401\n",
    "except Exception:\n",
    "    _pip_install(['transformers>=4.35'])\n",
    "\n",
    "# Utilities (optional but convenient)\n",
    "for pkg, import_name in [\n",
    "    ('tqdm', 'tqdm'),\n",
    "    ('scikit-learn', 'sklearn'),\n",
    "    ('pandas', 'pandas'),\n",
    "]:\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "    except Exception:\n",
    "        _pip_install([pkg])\n",
    "\n",
    "print('Python:', sys.version)\n",
    "import torch\n",
    "import transformers\n",
    "print('torch:', torch.__version__)\n",
    "print('transformers:', transformers.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d8bfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIPE_DATA_REPO_DIR = /content/hipe_cache/HIPE-2026-data\n",
      "SANDBOX_DIR = /content/hipe_cache/HIPE-2026-data/data/sandbox\n",
      "Sandbox JSONLs: ['de-dev.jsonl', 'de-train.jsonl', 'en-dev.jsonl', 'en-train.jsonl', 'fr-dev.jsonl', 'fr-train.jsonl']\n",
      "Train files: ['de-train.jsonl', 'en-train.jsonl', 'fr-train.jsonl']\n",
      "Dev file: en-dev.jsonl\n",
      "Train docs: 461 Train pairs: 6170\n",
      "Dev docs: 17 Dev pairs: 151\n",
      "Train label distribution: {'at': {'FALSE': 3669, 'PROBABLE': 1579, 'TRUE': 922}, 'isAt': {'FALSE': 5493, 'TRUE': 677}}\n",
      "Dev label distribution: {'at': {'FALSE': 68, 'PROBABLE': 54, 'TRUE': 29}, 'isAt': {'FALSE': 133, 'TRUE': 18}}\n"
     ]
    }
   ],
   "source": [
    "# Download/prepare the HIPE-2026 *data* repo locally inside this notebook runtime.\n",
    "# This replaces Google Drive mounting when you just want to pull the JSONL files from GitHub.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional\n",
    "\n",
    "HIPE_DATA_GITHUB_REPO = 'https://github.com/hipe-eval/HIPE-2026-data'\n",
    "WORK_DIR = Path.cwd()\n",
    "CACHE_DIR = WORK_DIR / 'hipe_cache'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def _download_file(url: str, dest: Path) -> None:\n",
    "    import urllib.request\n",
    "\n",
    "    with urllib.request.urlopen(url) as r, dest.open('wb') as f:\n",
    "        shutil.copyfileobj(r, f)\n",
    "\n",
    "\n",
    "def ensure_repo(repo_url: str, dest_dir: Path) -> Path:\n",
    "    \"\"\"Ensure a repo is present locally in this runtime; returns repo directory.\"\"\"\n",
    "    if (dest_dir / '.git').exists() or (dest_dir / 'README.md').exists():\n",
    "        return dest_dir\n",
    "\n",
    "    if dest_dir.exists():\n",
    "        # In case a previous partial download exists.\n",
    "        shutil.rmtree(dest_dir)\n",
    "\n",
    "    # Prefer git clone when available.\n",
    "    if shutil.which('git'):\n",
    "        print('Cloning repo with git...')\n",
    "        subprocess.check_call(['git', 'clone', '--depth', '1', repo_url, str(dest_dir)])\n",
    "        return dest_dir\n",
    "\n",
    "    # Fallback: download GitHub zip.\n",
    "    print('git not found; downloading zip archive...')\n",
    "    zip_url = repo_url.rstrip('/') + '/archive/refs/heads/main.zip'\n",
    "    zip_path = CACHE_DIR / (dest_dir.name + '-main.zip')\n",
    "    if not zip_path.exists():\n",
    "        _download_file(zip_url, zip_path)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(CACHE_DIR)\n",
    "\n",
    "    extracted = CACHE_DIR / (dest_dir.name + '-main')\n",
    "    if extracted.exists():\n",
    "        extracted.rename(dest_dir)\n",
    "        return dest_dir\n",
    "\n",
    "    # Some repos extract as <RepoName>-main\n",
    "    alt = CACHE_DIR / (repo_url.rstrip('/').split('/')[-1] + '-main')\n",
    "    if alt.exists():\n",
    "        alt.rename(dest_dir)\n",
    "        return dest_dir\n",
    "\n",
    "    raise FileNotFoundError('Zip extraction did not produce the expected folder.')\n",
    "\n",
    "\n",
    "HIPE_DATA_REPO_DIR = ensure_repo(HIPE_DATA_GITHUB_REPO, CACHE_DIR / 'HIPE-2026-data')\n",
    "print('HIPE_DATA_REPO_DIR =', HIPE_DATA_REPO_DIR)\n",
    "\n",
    "\n",
    "def find_hipe_sandbox_dir() -> Path:\n",
    "    \"\"\"Locate the HIPE sandbox folder.\n",
    "\n",
    "    Priority order:\n",
    "    1) The downloaded HIPE-2026-data repo\n",
    "    2) A local workspace clone (if you already have it)\n",
    "    3) Colab/Drive style paths\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        # Inside downloaded data repo\n",
    "        HIPE_DATA_REPO_DIR / 'data' / 'sandbox',\n",
    "\n",
    "        # Common local layouts (if you already have the data repo checked out)\n",
    "        Path.cwd() / 'HIPE-2026-data-main' / 'data' / 'sandbox',\n",
    "        Path('HIPE-2026-data-main') / 'data' / 'sandbox',\n",
    "        Path.cwd() / 'HIPE-2026-data' / 'data' / 'sandbox',\n",
    "        Path('HIPE-2026-data') / 'data' / 'sandbox',\n",
    "\n",
    "        # Common Colab Google Drive layouts\n",
    "        Path('/content/drive/My Drive/Colab Notebooks/HIPE-2026-data-main/data/sandbox'),\n",
    "        Path('/content/drive/My Drive/Jupyter Notebooks/HIPE-2026-data-main/data/sandbox'),\n",
    "        Path('/content/drive/My Drive/HIPE-2026-data-main/data/sandbox'),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists() and p.is_dir():\n",
    "            return p\n",
    "\n",
    "    # Robust fallback: search the downloaded repo for a directory named 'sandbox'\n",
    "    for p in HIPE_DATA_REPO_DIR.rglob('sandbox'):\n",
    "        if p.is_dir() and any(p.glob('*.jsonl')):\n",
    "            return p\n",
    "\n",
    "    raise FileNotFoundError('Could not find HIPE sandbox dir from common locations.')\n",
    "\n",
    "\n",
    "SANDBOX_DIR = find_hipe_sandbox_dir()\n",
    "print('SANDBOX_DIR =', SANDBOX_DIR)\n",
    "print('Sandbox JSONLs:', sorted([p.name for p in SANDBOX_DIR.glob('*.jsonl')])[:50])\n",
    "\n",
    "# --- Loading JSONL + building pair-level examples (used by the model cells below) ---\n",
    "def read_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "# Labels: treat null as \"FALSE\" (matches the official scorer's imputation rule)\n",
    "AT_LABELS = ['FALSE', 'PROBABLE', 'TRUE']\n",
    "ISAT_LABELS = ['FALSE', 'TRUE']\n",
    "AT2ID = {k: i for i, k in enumerate(AT_LABELS)}\n",
    "ID2AT = {i: k for k, i in AT2ID.items()}\n",
    "ISAT2ID = {k: i for i, k in enumerate(ISAT_LABELS)}\n",
    "ID2ISAT = {i: k for k, i in ISAT2ID.items()}\n",
    "\n",
    "def norm_at(v: Optional[str]) -> str:\n",
    "    return 'FALSE' if v is None else v\n",
    "\n",
    "def norm_isat(v: Optional[str]) -> str:\n",
    "    return 'FALSE' if v is None else v\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairExample:\n",
    "    document_id: str\n",
    "    pair_index: int\n",
    "    pers_entity_id: str\n",
    "    loc_entity_id: str\n",
    "    text: str\n",
    "    at: str\n",
    "    isAt: str\n",
    "\n",
    "\n",
    "def build_input_text(\n",
    "    doc_text: str,\n",
    "    pers_mentions: List[str],\n",
    "    loc_mentions: List[str],\n",
    "    *,\n",
    "    max_mentions: int = 2,\n",
    "    ) -> str:\n",
    "    pers = ' | '.join([m.replace('\\n', ' ').strip() for m in pers_mentions[:max_mentions]])\n",
    "    loc = ' | '.join([m.replace('\\n', ' ').strip() for m in loc_mentions[:max_mentions]])\n",
    "    ctx = doc_text.replace('\\n', ' ').strip()\n",
    "    return f\"Person: {pers}\\nLocation: {loc}\\nContext: {ctx}\"\n",
    "\n",
    "\n",
    "def iter_pair_examples(docs: List[Dict[str, Any]]) -> Iterable[PairExample]:\n",
    "    for doc in docs:\n",
    "        doc_id = doc['document_id']\n",
    "        doc_text = doc.get('text', '')\n",
    "        for idx, pair in enumerate(doc.get('sampled_pairs', [])):\n",
    "            yield PairExample(\n",
    "                document_id=doc_id,\n",
    "                pair_index=idx,\n",
    "                pers_entity_id=pair['pers_entity_id'],\n",
    "                loc_entity_id=pair['loc_entity_id'],\n",
    "                text=build_input_text(\n",
    "                    doc_text,\n",
    "                    pair.get('pers_mentions_list', []),\n",
    "                    pair.get('loc_mentions_list', []),\n",
    "                ),\n",
    "                at=norm_at(pair.get('at')),\n",
    "                isAt=norm_isat(pair.get('isAt')),\n",
    "            )\n",
    "\n",
    "\n",
    "def _sandbox_lang_from_filename(p: Path) -> str:\n",
    "    # e.g., en-train.jsonl -> en\n",
    "    return p.name.split('-', 1)[0]\n",
    "\n",
    "\n",
    "def list_sandbox_split_files(split: str, langs: Optional[List[str]] = None) -> List[Path]:\n",
    "    files = sorted(SANDBOX_DIR.glob(f\"*-{split}.jsonl\"))\n",
    "    if langs is None:\n",
    "        return files\n",
    "    want = set(langs)\n",
    "    return [p for p in files if _sandbox_lang_from_filename(p) in want]\n",
    "\n",
    "\n",
    "def load_docs_from_files(paths: List[Path]) -> List[Dict[str, Any]]:\n",
    "    docs: List[Dict[str, Any]] = []\n",
    "    for p in paths:\n",
    "        docs.extend(read_jsonl(p))\n",
    "    return docs\n",
    "\n",
    "\n",
    "def label_distribution(examples: List[PairExample]) -> Dict[str, Dict[str, int]]:\n",
    "    c_at = Counter(ex.at for ex in examples)\n",
    "    c_isat = Counter(ex.isAt for ex in examples)\n",
    "    return {\n",
    "        'at': {k: int(c_at.get(k, 0)) for k in AT_LABELS},\n",
    "        'isAt': {k: int(c_isat.get(k, 0)) for k in ISAT_LABELS},\n",
    "    }\n",
    "\n",
    "\n",
    "# By default: train on *all* sandbox train files; evaluate/export on one dev language.\n",
    "TRAIN_LANGS = ['en', 'de', 'fr']\n",
    "DEV_LANG = 'en'\n",
    "\n",
    "train_files = list_sandbox_split_files('train', TRAIN_LANGS)\n",
    "dev_files = list_sandbox_split_files('dev', [DEV_LANG])\n",
    "if len(train_files) == 0:\n",
    "    raise FileNotFoundError(f\"No '*-train.jsonl' files found in sandbox dir: {SANDBOX_DIR}\")\n",
    "if len(dev_files) != 1:\n",
    "    raise FileNotFoundError(f\"Expected exactly one dev file for DEV_LANG={DEV_LANG}, got: {dev_files}\")\n",
    "\n",
    "print('Train files:', [p.name for p in train_files])\n",
    "print('Dev file:', dev_files[0].name)\n",
    "\n",
    "train_docs = load_docs_from_files(train_files)\n",
    "dev_path = dev_files[0]\n",
    "dev_docs = read_jsonl(dev_path)\n",
    "\n",
    "train_ex = list(iter_pair_examples(train_docs))\n",
    "dev_ex = list(iter_pair_examples(dev_docs))\n",
    "\n",
    "print('Train docs:', len(train_docs), 'Train pairs:', len(train_ex))\n",
    "print('Dev docs:', len(dev_docs), 'Dev pairs:', len(dev_ex))\n",
    "print('Train label distribution:', label_distribution(train_ex))\n",
    "print('Dev label distribution:', label_distribution(dev_ex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29670b9d",
   "metadata": {},
   "source": [
    "## Model + training (next)\n",
    "Next cells will add:\n",
    "- Tokenization with `xlm-roberta-base`\n",
    "- A multi-task model with 2 heads:\n",
    "  - `at`: 3-way classification (`FALSE/PROBABLE/TRUE`)\n",
    "  - `isAt`: 2-way classification (`FALSE/TRUE`)\n",
    "- Training loop + dev evaluation\n",
    "- Export predictions to HIPE JSONL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb59036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tokenizer loaded: xlm-roberta-base\n",
      "Model loaded: xlm-roberta-base\n",
      "DROPOUT = 0.2\n",
      "EPOCHS = 6\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "MODEL_NAME = 'xlm-roberta-base'\n",
    "MAX_LEN = 182\n",
    "BATCH_SIZE = 32\n",
    "LR = 2e-5\n",
    "EPOCHS = 6\n",
    "WARMUP_RATIO = 0.06\n",
    "SEED = 42\n",
    "DROPOUT = 0.2\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    import random\n",
    "    import numpy as np\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print('Tokenizer loaded:', MODEL_NAME)\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, examples: Sequence[PairExample]):\n",
    "        self.examples = list(examples)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        ex = self.examples[idx]\n",
    "        enc = tokenizer(\n",
    "            ex.text,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=MAX_LEN,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'],\n",
    "            'attention_mask': enc['attention_mask'],\n",
    "            'label_at': AT2ID[ex.at],\n",
    "            'label_isAt': ISAT2ID[ex.isAt],\n",
    "        }\n",
    "\n",
    "def collate_batch(batch: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "    input_ids = [torch.tensor(x['input_ids'], dtype=torch.long) for x in batch]\n",
    "    attention_mask = [torch.tensor(x['attention_mask'], dtype=torch.long) for x in batch]\n",
    "    input_ids = nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = nn.utils.rnn.pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "\n",
    "    label_at = torch.tensor([x['label_at'] for x in batch], dtype=torch.long)\n",
    "    label_isAt = torch.tensor([x['label_isAt'] for x in batch], dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'label_at': label_at,\n",
    "        'label_isAt': label_isAt,\n",
    "    }\n",
    "\n",
    "class MultiTaskXLMR(nn.Module):\n",
    "    def __init__(self, model_name: str = MODEL_NAME, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        hidden = self.encoder.config.hidden_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.head_at = nn.Linear(hidden, len(AT_LABELS))\n",
    "        self.head_isAt = nn.Linear(hidden, len(ISAT_LABELS))\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # XLM-R has no pooler by default; use CLS token representation.\n",
    "        cls = out.last_hidden_state[:, 0, :]\n",
    "        x = self.dropout(cls)\n",
    "        return {\n",
    "            'logits_at': self.head_at(x),\n",
    "            'logits_isAt': self.head_isAt(x),\n",
    "        }\n",
    "\n",
    "model = MultiTaskXLMR(MODEL_NAME, dropout=DROPOUT).to(device)\n",
    "print('Model loaded:', MODEL_NAME)\n",
    "print('DROPOUT =', DROPOUT)\n",
    "print('EPOCHS =', EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a509bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sampling: WeightedRandomSampler (oversampling enabled)\n",
      "Augmentation: True | AUG_PROB: 0.5 | ctx_window_chars: 900\n",
      "Oversampling: True | weight_decay: 0.01\n",
      "Early stopping: True | patience: 2 | best metric: recall_avg_macro\n",
      "Train batches: 193 Dev batches: 5\n",
      "Total steps: 1158 Warmup: 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942fed7e9bcf419ea75cf0d98160dcc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/6:   0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress so far:\n",
      " epoch  train_loss  val_loss       lr  acc_at  acc_isAt  acc_avg  recall_at_macro  recall_isAt_macro  recall_avg_macro\n",
      "   1.0      1.7679    2.0002 1.77e-05  0.2053    0.3377   0.2715             0.33             0.4559            0.3929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2499237e7000468da7de2f51ecac16d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/6:   0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress so far:\n",
      " epoch  train_loss  val_loss       lr  acc_at  acc_isAt  acc_avg  recall_at_macro  recall_isAt_macro  recall_avg_macro\n",
      "   1.0      1.7679    2.0002 1.77e-05  0.2053    0.3377   0.2715           0.3300             0.4559            0.3929\n",
      "   2.0      1.5160    1.7575 1.42e-05  0.4437    0.6887   0.5662           0.4753             0.5831            0.5292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577da7baab6447bca93c220a503c4140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/6:   0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress so far:\n",
      " epoch  train_loss  val_loss       lr  acc_at  acc_isAt  acc_avg  recall_at_macro  recall_isAt_macro  recall_avg_macro\n",
      "   1.0      1.7679    2.0002 1.77e-05  0.2053    0.3377   0.2715           0.3300             0.4559            0.3929\n",
      "   2.0      1.5160    1.7575 1.42e-05  0.4437    0.6887   0.5662           0.4753             0.5831            0.5292\n",
      "   3.0      1.2859    2.1292 1.06e-05  0.3510    0.5629   0.4570           0.4039             0.5838            0.4938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6859402552f497890c6c3d6921c563b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/6:   0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress so far:\n",
      " epoch  train_loss  val_loss       lr  acc_at  acc_isAt  acc_avg  recall_at_macro  recall_isAt_macro  recall_avg_macro\n",
      "   1.0      1.7679    2.0002 1.77e-05  0.2053    0.3377   0.2715           0.3300             0.4559            0.3929\n",
      "   2.0      1.5160    1.7575 1.42e-05  0.4437    0.6887   0.5662           0.4753             0.5831            0.5292\n",
      "   3.0      1.2859    2.1292 1.06e-05  0.3510    0.5629   0.4570           0.4039             0.5838            0.4938\n",
      "   4.0      1.0950    2.0999 7.09e-06  0.4437    0.6887   0.5662           0.4581             0.6552            0.5566\n",
      "\n",
      "Early stopping: val_loss did not improve for 2 epoch(s).\n",
      "\n",
      "Restored best model from epoch 4 (best recall_avg_macro=0.5566).\n",
      "Best model dev metrics: {'acc_at': 0.44370860927152317, 'acc_isAt': 0.6887417218543046, 'acc_avg': 0.5662251655629139, 'recall_at_macro': 0.4580547416923347, 'recall_isAt_macro': 0.6551796157059315, 'recall_avg_macro': 0.5566171786991331, 'val_loss': 2.0998814582824705}\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from collections import Counter\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_batches(model: nn.Module, loader: DataLoader) -> Tuple[List[int], List[int]]:\n",
    "    model.eval()\n",
    "    preds_at: List[int] = []\n",
    "    preds_isAt: List[int] = []\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds_at.extend(out['logits_at'].argmax(dim=-1).tolist())\n",
    "        preds_isAt.extend(out['logits_isAt'].argmax(dim=-1).tolist())\n",
    "    return preds_at, preds_isAt\n",
    "\n",
    "def evaluate_simple(model: nn.Module, loader: DataLoader) -> Dict[str, float]:\n",
    "    y_at: List[int] = []\n",
    "    y_isAt: List[int] = []\n",
    "    for batch in loader:\n",
    "        y_at.extend(batch['label_at'].tolist())\n",
    "        y_isAt.extend(batch['label_isAt'].tolist())\n",
    "\n",
    "    p_at, p_isAt = predict_batches(model, loader)\n",
    "\n",
    "    acc_at = accuracy_score(y_at, p_at)\n",
    "    acc_isAt = accuracy_score(y_isAt, p_isAt)\n",
    "\n",
    "    # Macro recall across classes (handles class imbalance better than accuracy).\n",
    "    # Force label set so missing classes don't crash; zero_division=0 avoids warnings.\n",
    "    rec_at_macro = recall_score(\n",
    "        y_at,\n",
    "        p_at,\n",
    "        average='macro',\n",
    "        labels=list(range(len(AT_LABELS))),\n",
    "        zero_division=0,\n",
    "    )\n",
    "    rec_isAt_macro = recall_score(\n",
    "        y_isAt,\n",
    "        p_isAt,\n",
    "        average='macro',\n",
    "        labels=list(range(len(ISAT_LABELS))),\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'acc_at': float(acc_at),\n",
    "        'acc_isAt': float(acc_isAt),\n",
    "        'acc_avg': float(0.5 * (acc_at + acc_isAt)),\n",
    "        'recall_at_macro': float(rec_at_macro),\n",
    "        'recall_isAt_macro': float(rec_isAt_macro),\n",
    "        'recall_avg_macro': float(0.5 * (rec_at_macro + rec_isAt_macro)),\n",
    "    }\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_val_loss(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    *,\n",
    "    criterion_at: nn.Module,\n",
    "    criterion_isAt: nn.Module,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    batches = 0\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        label_at = batch['label_at'].to(device)\n",
    "        label_isAt = batch['label_isAt'].to(device)\n",
    "\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss_at = criterion_at(out['logits_at'], label_at)\n",
    "        loss_isAt = criterion_isAt(out['logits_isAt'], label_isAt)\n",
    "        loss = loss_at + loss_isAt\n",
    "        total += float(loss.item())\n",
    "        batches += 1\n",
    "    return float(total / max(1, batches))\n",
    "\n",
    "def parse_prompt_text(text: str) -> Tuple[List[str], List[str], str]:\n",
    "    \"\"\"Extract mentions + context from our formatted prompt string.\"\"\"\n",
    "    pers_mentions: List[str] = []\n",
    "    loc_mentions: List[str] = []\n",
    "    ctx = \"\"\n",
    "    for raw in text.splitlines():\n",
    "        line = raw.strip()\n",
    "        if line.startswith('Person:'):\n",
    "            pers_mentions = [m.strip() for m in line[len('Person:'):].split('|') if m.strip()]\n",
    "        elif line.startswith('Location:'):\n",
    "            loc_mentions = [m.strip() for m in line[len('Location:'):].split('|') if m.strip()]\n",
    "        elif line.startswith('Context:'):\n",
    "            ctx = line[len('Context:'):].strip()\n",
    "    return pers_mentions, loc_mentions, ctx\n",
    "\n",
    "def crop_context(ctx: str, pers_mentions: List[str], loc_mentions: List[str], *, window_chars: int = 900) -> str:\n",
    "    if len(ctx) <= window_chars:\n",
    "        return ctx\n",
    "    # Try to center around first occurrence of a person/location mention\n",
    "    needles = [m for m in (pers_mentions[:1] + loc_mentions[:1]) if m]\n",
    "    centers: List[int] = []\n",
    "    for needle in needles:\n",
    "        pos = ctx.lower().find(needle.lower())\n",
    "        if pos >= 0:\n",
    "            centers.append(pos)\n",
    "    if centers:\n",
    "        center = min(centers)\n",
    "        start = max(0, center - window_chars // 2)\n",
    "    else:\n",
    "        start = random.randint(0, max(0, len(ctx) - window_chars))\n",
    "    end = min(len(ctx), start + window_chars)\n",
    "    snippet = ctx[start:end].strip()\n",
    "    return snippet\n",
    "\n",
    "def augment_prompt_text(text: str, *, window_chars: int = 900, drop_prob: float = 0.35, shuffle_mentions: bool = True) -> str:\n",
    "    pers_mentions, loc_mentions, ctx = parse_prompt_text(text)\n",
    "    # Mention dropout (keep at least 1)\n",
    "    def _drop(ms: List[str]) -> List[str]:\n",
    "        if len(ms) <= 1:\n",
    "            return ms\n",
    "        kept = [m for m in ms if random.random() > drop_prob]\n",
    "        return kept if kept else [random.choice(ms)]\n",
    "    pers_mentions = _drop(pers_mentions)\n",
    "    loc_mentions = _drop(loc_mentions)\n",
    "    if shuffle_mentions:\n",
    "        random.shuffle(pers_mentions)\n",
    "        random.shuffle(loc_mentions)\n",
    "    ctx = crop_context(ctx, pers_mentions, loc_mentions, window_chars=window_chars)\n",
    "    pers = ' | '.join(pers_mentions)\n",
    "    loc = ' | '.join(loc_mentions)\n",
    "    return f\"Person: {pers}\\nLocation: {loc}\\nContext: {ctx}\"\n",
    "\n",
    "class AugmentedPairDataset(Dataset):\n",
    "    def __init__(self, examples: Sequence[PairExample], *, augment: bool, aug_prob: float, window_chars: int):\n",
    "        self.examples = list(examples)\n",
    "        self.augment = bool(augment)\n",
    "        self.aug_prob = float(aug_prob)\n",
    "        self.window_chars = int(window_chars)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        ex = self.examples[idx]\n",
    "        text = ex.text\n",
    "        if self.augment and random.random() < self.aug_prob:\n",
    "            text = augment_prompt_text(text, window_chars=self.window_chars)\n",
    "        enc = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=MAX_LEN,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'],\n",
    "            'attention_mask': enc['attention_mask'],\n",
    "            'label_at': AT2ID[ex.at],\n",
    "            'label_isAt': ISAT2ID[ex.isAt],\n",
    "        }\n",
    "\n",
    "def make_train_sampler(examples: List[PairExample]) -> WeightedRandomSampler:\n",
    "    \"\"\"Oversample rarer labels (both tasks) using a per-example weight.\"\"\"\n",
    "    at_counts = Counter(ex.at for ex in examples)\n",
    "    isat_counts = Counter(ex.isAt for ex in examples)\n",
    "    # Inverse-frequency weights; sqrt dampens extreme oversampling.\n",
    "    inv_at = {k: (len(examples) / max(1, at_counts.get(k, 0))) for k in AT_LABELS}\n",
    "    inv_isat = {k: (len(examples) / max(1, isat_counts.get(k, 0))) for k in ISAT_LABELS}\n",
    "    weights = []\n",
    "    for ex in examples:\n",
    "        w = (inv_at[ex.at] * inv_isat[ex.isAt]) ** 0.5\n",
    "        weights.append(float(w))\n",
    "    w_t = torch.tensor(weights, dtype=torch.double)\n",
    "    return WeightedRandomSampler(weights=w_t, num_samples=len(examples), replacement=True)\n",
    "\n",
    "# --- Augmentation toggles (train only) ---\n",
    "USE_AUGMENTATION = True\n",
    "AUG_PROB = 0.50\n",
    "AUG_CONTEXT_WINDOW_CHARS = 900\n",
    "\n",
    "train_ds = AugmentedPairDataset(train_ex, augment=USE_AUGMENTATION, aug_prob=AUG_PROB, window_chars=AUG_CONTEXT_WINDOW_CHARS)\n",
    "dev_ds = AugmentedPairDataset(dev_ex, augment=False, aug_prob=0.0, window_chars=AUG_CONTEXT_WINDOW_CHARS)\n",
    "\n",
    "# --- Imbalance + regularization toggles ---\n",
    "USE_OVERSAMPLING = True\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "if USE_OVERSAMPLING:\n",
    "    sampler = make_train_sampler(train_ex)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, shuffle=False, collate_fn=collate_batch)\n",
    "    print('Train sampling: WeightedRandomSampler (oversampling enabled)')\n",
    "else:\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "    print('Train sampling: shuffle=True')\n",
    "\n",
    "dev_loader = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "criterion_at = nn.CrossEntropyLoss()\n",
    "criterion_isAt = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "num_steps = EPOCHS * len(train_loader)\n",
    "warmup_steps = int(WARMUP_RATIO * num_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_steps)\n",
    "\n",
    "# --- Early stopping / best checkpoint ---\n",
    "EARLY_STOPPING = True\n",
    "EARLY_STOP_PATIENCE = 4\n",
    "EARLY_STOP_MIN_DELTA = 0.0\n",
    "BEST_MODEL_METRIC = 'recall_avg_macro'  # or 'val_loss' if you prefer\n",
    "_best_state = None\n",
    "_best_epoch = None\n",
    "_best_metric_val = None\n",
    "_best_val_loss = None\n",
    "_no_improve = 0\n",
    "\n",
    "print('Augmentation:', USE_AUGMENTATION, '| AUG_PROB:', AUG_PROB, '| ctx_window_chars:', AUG_CONTEXT_WINDOW_CHARS)\n",
    "print('Oversampling:', USE_OVERSAMPLING, '| weight_decay:', WEIGHT_DECAY)\n",
    "print('Early stopping:', EARLY_STOPPING, '| patience:', EARLY_STOP_PATIENCE, '| best metric:', BEST_MODEL_METRIC)\n",
    "print('Train batches:', len(train_loader), 'Dev batches:', len(dev_loader))\n",
    "print('Total steps:', num_steps, 'Warmup:', warmup_steps)\n",
    "\n",
    "history: List[Dict[str, float]] = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "\n",
    "    pbar = tqdm(\n",
    "        enumerate(train_loader, start=1),\n",
    "        total=len(train_loader),\n",
    "        desc=f\"Epoch {epoch}/{EPOCHS}\",\n",
    "        leave=True,\n",
    "    )\n",
    "    for step, batch in pbar:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        label_at = batch['label_at'].to(device)\n",
    "        label_isAt = batch['label_isAt'].to(device)\n",
    "\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss_at = criterion_at(out['logits_at'], label_at)\n",
    "        loss_isAt = criterion_isAt(out['logits_isAt'], label_isAt)\n",
    "        loss = loss_at + loss_isAt\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running += float(loss.item())\n",
    "        if step % 5 == 0 or step == len(train_loader):\n",
    "            pbar.set_postfix(\n",
    "                train_loss=f\"{running / step:.4f}\",\n",
    "                lr=f\"{optimizer.param_groups[0]['lr']:.2e}\",\n",
    "            )\n",
    "\n",
    "    metrics = evaluate_simple(model, dev_loader)\n",
    "    val_loss = compute_val_loss(model, dev_loader, criterion_at=criterion_at, criterion_isAt=criterion_isAt)\n",
    "    lr_now = float(optimizer.param_groups[0]['lr'])\n",
    "    row = {\n",
    "        'epoch': float(epoch),\n",
    "        'train_loss': float(running / max(1, len(train_loader))),\n",
    "        'val_loss': float(val_loss),\n",
    "        'lr': lr_now,\n",
    "        **metrics,\n",
    "    }\n",
    "    history.append(row)\n",
    "\n",
    "    # Track best checkpoint (defaults to macro recall avg)\n",
    "    metric_val = float(row[BEST_MODEL_METRIC])\n",
    "    if _best_metric_val is None or metric_val > _best_metric_val:\n",
    "        _best_metric_val = metric_val\n",
    "        _best_epoch = epoch\n",
    "        _best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Early stop based on validation loss (more stable than recall)\n",
    "    if _best_val_loss is None or val_loss < (_best_val_loss - EARLY_STOP_MIN_DELTA):\n",
    "        _best_val_loss = float(val_loss)\n",
    "        _no_improve = 0\n",
    "    else:\n",
    "        _no_improve += 1\n",
    "\n",
    "    df = pd.DataFrame(history)\n",
    "    # Pretty print with stable column order\n",
    "    cols = [\n",
    "        'epoch',\n",
    "        'train_loss',\n",
    "        'val_loss',\n",
    "        'lr',\n",
    "        'acc_at',\n",
    "        'acc_isAt',\n",
    "        'acc_avg',\n",
    "        'recall_at_macro',\n",
    "        'recall_isAt_macro',\n",
    "        'recall_avg_macro',\n",
    "    ]\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    df_show = df[cols].copy()\n",
    "    if 'lr' in df_show.columns:\n",
    "        df_show['lr'] = df_show['lr'].map(lambda x: f\"{float(x):.2e}\")\n",
    "    print('\\nProgress so far:')\n",
    "    print(df_show.round(4).to_string(index=False))\n",
    "\n",
    "    if EARLY_STOPPING and _no_improve >= EARLY_STOP_PATIENCE:\n",
    "        print(f\"\\nEarly stopping: val_loss did not improve for {EARLY_STOP_PATIENCE} epoch(s).\")\n",
    "        break\n",
    "\n",
    "# Restore best checkpoint (by BEST_MODEL_METRIC) and report\n",
    "if _best_state is not None:\n",
    "    model.load_state_dict(_best_state)\n",
    "    best_metrics = evaluate_simple(model, dev_loader)\n",
    "    best_val_loss = compute_val_loss(model, dev_loader, criterion_at=criterion_at, criterion_isAt=criterion_isAt)\n",
    "    print(f\"\\nRestored best model from epoch {_best_epoch} (best {BEST_MODEL_METRIC}={_best_metric_val:.4f}).\")\n",
    "    print('Best model dev metrics:', {**best_metrics, 'val_loss': float(best_val_loss)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5727d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "935628b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /content/en_dev_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "def write_predictions_jsonl(\n",
    "    docs: List[Dict[str, Any]],\n",
    "    examples: List[PairExample],\n",
    "    pred_at_ids: List[int],\n",
    "    pred_isat_ids: List[int],\n",
    "    out_path: Path,\n",
    ") -> None:\n",
    "    \"\"\"Write a HIPE-format JSONL file.\n",
    "\n",
    "    We preserve the original doc fields, and overwrite each pair's `at` and `isAt` with predictions.\n",
    "    \"\"\"\n",
    "    assert len(examples) == len(pred_at_ids) == len(pred_isat_ids)\n",
    "\n",
    "    # Group predictions by doc_id and pair_index\n",
    "    by_doc: Dict[str, Dict[int, Tuple[str, str]]] = {}\n",
    "    for ex, a_id, i_id in zip(examples, pred_at_ids, pred_isat_ids):\n",
    "        by_doc.setdefault(ex.document_id, {})[ex.pair_index] = (ID2AT[int(a_id)], ID2ISAT[int(i_id)])\n",
    "\n",
    "    with out_path.open('w', encoding='utf-8') as f:\n",
    "        for doc in docs:\n",
    "            doc_id = doc['document_id']\n",
    "            new_doc = dict(doc)\n",
    "            new_pairs = []\n",
    "            for idx, pair in enumerate(doc.get('sampled_pairs', [])):\n",
    "                new_pair = dict(pair)\n",
    "                at_pred, isat_pred = by_doc.get(doc_id, {}).get(idx, ('FALSE', 'FALSE'))\n",
    "                new_pair['at'] = at_pred\n",
    "                new_pair['isAt'] = isat_pred\n",
    "                new_pairs.append(new_pair)\n",
    "            new_doc['sampled_pairs'] = new_pairs\n",
    "            f.write(json.dumps(new_doc, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# Export dev predictions (for DEV_LANG)\n",
    "p_at_dev, p_isAt_dev = predict_batches(model, dev_loader)\n",
    "dev_lang = globals().get('DEV_LANG', 'dev')\n",
    "output_path = Path.cwd() / f'{dev_lang}_dev_predictions.jsonl'\n",
    "write_predictions_jsonl(dev_docs, dev_ex, p_at_dev, p_isAt_dev, output_path)\n",
    "print('Wrote:', output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceec51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
