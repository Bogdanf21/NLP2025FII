{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b41e03c",
   "metadata": {},
   "source": [
    "# HIPE-2026 People–Place Context — Evidence MIL (Alternative Architecture)\n",
    "This notebook implements a **different** approach than the cross-encoder baselines:\n",
    "- Encode each document as a set of overlapping **windows** (evidence units)\n",
    "- Precompute **frozen window embeddings** with `xlm-roberta-base`\n",
    "- Precompute **frozen entity embeddings** from the person/place mention strings\n",
    "- For each `(person, location)` pair, use **multi-instance learning (MIL)**: attention selects the most relevant windows\n",
    "- Predict two labels per pair:\n",
    "  - `at`: 3-way (`FALSE/PROBABLE/TRUE`)\n",
    "  - `isAt`: 2-way (`FALSE/TRUE`)\n",
    "- Export predictions back to HIPE JSONL format by overwriting `sampled_pairs[*].at` and `sampled_pairs[*].isAt`.\n",
    "\n",
    "Why this is a different architecture: we do **not** re-encode the entire prompt per pair. The heavy transformer encoder is run **per document window**, cached, and pair scoring is done by a lightweight attention+MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76a9522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "torch: 2.9.0+cu126\n",
      "transformers: 4.57.3\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "# 1) Install & verify dependencies\n",
    "import sys\n",
    "import subprocess\n",
    "def _pip_install(pkgs):\n",
    "    cmd = [sys.executable, '-m', 'pip', 'install', '-q'] + list(pkgs)\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# Core ML deps\n",
    "try:\n",
    "    import torch  # noqa: F401\n",
    "except Exception:\n",
    "    _pip_install(['torch'])\n",
    "\n",
    "try:\n",
    "    import transformers  # noqa: F401\n",
    "except Exception:\n",
    "    _pip_install(['transformers>=4.35'])\n",
    "\n",
    "# Utilities\n",
    "for pkg, import_name in [\n",
    "    ('tqdm', 'tqdm'),\n",
    "    ('scikit-learn', 'sklearn'),\n",
    "    ('pandas', 'pandas'),\n",
    "    ('numpy', 'numpy'),\n",
    "]:\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "    except Exception:\n",
    "        _pip_install([pkg])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "print('Python:', sys.version)\n",
    "print('torch:', torch.__version__)\n",
    "print('transformers:', transformers.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334fde36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIPE_DATA_REPO_DIR = /content/hipe_cache/HIPE-2026-data\n",
      "SANDBOX_DIR = /content/hipe_cache/HIPE-2026-data/data/sandbox\n",
      "Sandbox JSONLs: ['de-dev.jsonl', 'de-train.jsonl', 'en-dev.jsonl', 'en-train.jsonl', 'fr-dev.jsonl', 'fr-train.jsonl']\n"
     ]
    }
   ],
   "source": [
    "# 2) Download/cache HIPE-2026 data repo + locate sandbox directory (same approach as test.ipynb)\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Iterable, Tuple\n",
    "HIPE_DATA_GITHUB_REPO = 'https://github.com/hipe-eval/HIPE-2026-data'\n",
    "WORK_DIR = Path.cwd()\n",
    "CACHE_DIR = WORK_DIR / 'hipe_cache'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _download_file(url: str, dest: Path) -> None:\n",
    "    import urllib.request\n",
    "    with urllib.request.urlopen(url) as r, dest.open('wb') as f:\n",
    "        shutil.copyfileobj(r, f)\n",
    "\n",
    "def ensure_repo(repo_url: str, dest_dir: Path) -> Path:\n",
    "    if (dest_dir / '.git').exists() or (dest_dir / 'README.md').exists():\n",
    "        return dest_dir\n",
    "    if dest_dir.exists():\n",
    "        shutil.rmtree(dest_dir)\n",
    "    if shutil.which('git'):\n",
    "        print('Cloning repo with git...')\n",
    "        subprocess.check_call(['git', 'clone', '--depth', '1', repo_url, str(dest_dir)])\n",
    "        return dest_dir\n",
    "    print('git not found; downloading zip archive...')\n",
    "    zip_url = repo_url.rstrip('/') + '/archive/refs/heads/main.zip'\n",
    "    zip_path = CACHE_DIR / (dest_dir.name + '-main.zip')\n",
    "    if not zip_path.exists():\n",
    "        _download_file(zip_url, zip_path)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(CACHE_DIR)\n",
    "    extracted = CACHE_DIR / (dest_dir.name + '-main')\n",
    "    if extracted.exists():\n",
    "        extracted.rename(dest_dir)\n",
    "        return dest_dir\n",
    "    alt = CACHE_DIR / (repo_url.rstrip('/').split('/')[-1] + '-main')\n",
    "    if alt.exists():\n",
    "        alt.rename(dest_dir)\n",
    "        return dest_dir\n",
    "    raise FileNotFoundError('Zip extraction did not produce the expected folder.')\n",
    "\n",
    "HIPE_DATA_REPO_DIR = ensure_repo(HIPE_DATA_GITHUB_REPO, CACHE_DIR / 'HIPE-2026-data')\n",
    "print('HIPE_DATA_REPO_DIR =', HIPE_DATA_REPO_DIR)\n",
    "\n",
    "def find_hipe_sandbox_dir() -> Path:\n",
    "    candidates = [\n",
    "        HIPE_DATA_REPO_DIR / 'data' / 'sandbox',\n",
    "        Path.cwd() / 'HIPE-2026-data-main' / 'data' / 'sandbox',\n",
    "        Path('HIPE-2026-data-main') / 'data' / 'sandbox',\n",
    "        Path.cwd() / 'HIPE-2026-data' / 'data' / 'sandbox',\n",
    "        Path('HIPE-2026-data') / 'data' / 'sandbox',\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists() and p.is_dir():\n",
    "            return p\n",
    "    for p in HIPE_DATA_REPO_DIR.rglob('sandbox'):\n",
    "        if p.is_dir() and any(p.glob('*.jsonl')):\n",
    "            return p\n",
    "    raise FileNotFoundError('Could not find HIPE sandbox dir from common locations.')\n",
    "\n",
    "SANDBOX_DIR = find_hipe_sandbox_dir()\n",
    "print('SANDBOX_DIR =', SANDBOX_DIR)\n",
    "print('Sandbox JSONLs:', sorted([p.name for p in SANDBOX_DIR.glob('*.jsonl')])[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: ['de-train.jsonl', 'en-train.jsonl', 'fr-train.jsonl']\n",
      "Dev file: en-dev.jsonl\n",
      "Train docs: 461 Train pairs: 6170\n",
      "Dev docs: 17 Dev pairs: 151\n",
      "Train label distribution: {'at': {'FALSE': 3669, 'PROBABLE': 1579, 'TRUE': 922}, 'isAt': {'FALSE': 5493, 'TRUE': 677}}\n",
      "Dev label distribution: {'at': {'FALSE': 68, 'PROBABLE': 54, 'TRUE': 29}, 'isAt': {'FALSE': 133, 'TRUE': 18}}\n",
      "Train pairs by language: {'fr': 4450, 'de': 1224, 'en': 496}\n",
      "Dev pairs by language: {'en': 151}\n"
     ]
    }
   ],
   "source": [
    "# 3) Load JSONL splits + build pair examples + EDA\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import math\n",
    "import random\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "def read_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _sandbox_lang_from_filename(p: Path) -> str:\n",
    "    return p.name.split('-', 1)[0]\n",
    "\n",
    "\n",
    "def list_sandbox_split_files(split: str, langs: Optional[List[str]] = None) -> List[Path]:\n",
    "    files = sorted(SANDBOX_DIR.glob(f\"*-{split}.jsonl\"))\n",
    "    if langs is None:\n",
    "        return files\n",
    "    want = set(langs)\n",
    "    return [p for p in files if _sandbox_lang_from_filename(p) in want]\n",
    "\n",
    "\n",
    "def load_docs_from_files(paths: List[Path]) -> List[Dict[str, Any]]:\n",
    "    docs: List[Dict[str, Any]] = []\n",
    "    for p in paths:\n",
    "        docs.extend(read_jsonl(p))\n",
    "    return docs\n",
    "\n",
    "\n",
    "# Labels (baseline-compatible): null -> FALSE\n",
    "AT_LABELS = ['FALSE', 'PROBABLE', 'TRUE']\n",
    "ISAT_LABELS = ['FALSE', 'TRUE']\n",
    "AT2ID = {k: i for i, k in enumerate(AT_LABELS)}\n",
    "ID2AT = {i: k for k, i in AT2ID.items()}\n",
    "ISAT2ID = {k: i for i, k in enumerate(ISAT_LABELS)}\n",
    "ID2ISAT = {i: k for k, i in ISAT2ID.items()}\n",
    "\n",
    "\n",
    "def norm_at(v: Optional[str]) -> str:\n",
    "    return 'FALSE' if v is None else str(v)\n",
    "\n",
    "def norm_isat(v: Optional[str]) -> str:\n",
    "    return 'FALSE' if v is None else str(v)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairExampleMIL:\n",
    "    document_id: str\n",
    "    pair_index: int\n",
    "    language: str\n",
    "    date: str\n",
    "    doc_text: str\n",
    "    pers_entity_id: str\n",
    "    loc_entity_id: str\n",
    "    pers_mentions: List[str]\n",
    "    loc_mentions: List[str]\n",
    "    pers_mention: str\n",
    "    loc_mention: str\n",
    "    at: str\n",
    "    isAt: str\n",
    "\n",
    "\n",
    "def _normalize_mentions_list(xs: Any) -> List[str]:\n",
    "    if not isinstance(xs, list):\n",
    "        return []\n",
    "    out: List[str] = []\n",
    "    seen = set()\n",
    "    for x in xs:\n",
    "        if not isinstance(x, str):\n",
    "            continue\n",
    "        s = x.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        if s in seen:\n",
    "            continue\n",
    "        seen.add(s)\n",
    "        out.append(s)\n",
    "    return out\n",
    "\n",
    "\n",
    "def iter_pair_examples_mil(docs: List[Dict[str, Any]]) -> List[PairExampleMIL]:\n",
    "    out: List[PairExampleMIL] = []\n",
    "    for doc in docs:\n",
    "        doc_id = str(doc.get('document_id') or doc.get('doc_id') or doc.get('id') or '')\n",
    "        if not doc_id:\n",
    "            continue\n",
    "        lang = str(doc.get('language') or '')\n",
    "        date = str(doc.get('date') or doc.get('publication_date') or '')\n",
    "        text = str(doc.get('text') or '')\n",
    "        pairs = doc.get('sampled_pairs')\n",
    "        if not text or not isinstance(pairs, list):\n",
    "            continue\n",
    "        for idx, pair in enumerate(pairs):\n",
    "            if not isinstance(pair, dict):\n",
    "                continue\n",
    "            pers_id = str(pair.get('pers_entity_id') or '')\n",
    "            loc_id = str(pair.get('loc_entity_id') or '')\n",
    "            if not pers_id or not loc_id:\n",
    "                continue\n",
    "\n",
    "            pers_ms = _normalize_mentions_list(pair.get('pers_mentions_list'))\n",
    "            loc_ms = _normalize_mentions_list(pair.get('loc_mentions_list'))\n",
    "            pers_m = pers_ms[0] if pers_ms else ''\n",
    "            loc_m = loc_ms[0] if loc_ms else ''\n",
    "\n",
    "            out.append(PairExampleMIL(\n",
    "                document_id=doc_id,\n",
    "                pair_index=idx,\n",
    "                language=lang,\n",
    "                date=date,\n",
    "                doc_text=text,\n",
    "                pers_entity_id=pers_id,\n",
    "                loc_entity_id=loc_id,\n",
    "                pers_mentions=pers_ms,\n",
    "                loc_mentions=loc_ms,\n",
    "                pers_mention=pers_m,\n",
    "                loc_mention=loc_m,\n",
    "                at=norm_at(pair.get('at')),\n",
    "                isAt=norm_isat(pair.get('isAt')),\n",
    "            ))\n",
    "    return out\n",
    "\n",
    "\n",
    "# Config: multilingual train, single-language dev\n",
    "TRAIN_LANGS = ['en', 'de', 'fr']\n",
    "DEV_LANG = 'en'\n",
    "train_files = list_sandbox_split_files('train', TRAIN_LANGS)\n",
    "dev_files = list_sandbox_split_files('dev', [DEV_LANG])\n",
    "if len(train_files) == 0:\n",
    "    raise FileNotFoundError(f\"No '*-train.jsonl' files found in {SANDBOX_DIR}\")\n",
    "if len(dev_files) != 1:\n",
    "    raise FileNotFoundError(f\"Expected exactly one dev file for DEV_LANG={DEV_LANG}, got: {dev_files}\")\n",
    "print('Train files:', [p.name for p in train_files])\n",
    "print('Dev file:', dev_files[0].name)\n",
    "\n",
    "train_docs = load_docs_from_files(train_files)\n",
    "dev_docs = read_jsonl(dev_files[0])\n",
    "train_ex = iter_pair_examples_mil(train_docs)\n",
    "dev_ex = iter_pair_examples_mil(dev_docs)\n",
    "print('Train docs:', len(train_docs), 'Train pairs:', len(train_ex))\n",
    "print('Dev docs:', len(dev_docs), 'Dev pairs:', len(dev_ex))\n",
    "\n",
    "\n",
    "def label_distribution(examples: List[PairExampleMIL]) -> Dict[str, Dict[str, int]]:\n",
    "    c_at = Counter(ex.at for ex in examples)\n",
    "    c_is = Counter(ex.isAt for ex in examples)\n",
    "    return {\n",
    "        'at': {k: int(c_at.get(k, 0)) for k in AT_LABELS},\n",
    "        'isAt': {k: int(c_is.get(k, 0)) for k in ISAT_LABELS},\n",
    "    }\n",
    "\n",
    "print('Train label distribution:', label_distribution(train_ex))\n",
    "print('Dev label distribution:', label_distribution(dev_ex))\n",
    "\n",
    "\n",
    "# Per-language counts (quick EDA)\n",
    "def counts_by_lang(examples: List[PairExampleMIL]) -> Dict[str, int]:\n",
    "    c = Counter(ex.language for ex in examples)\n",
    "    return dict(sorted(c.items(), key=lambda x: (-x[1], x[0])))\n",
    "\n",
    "print('Train pairs by language:', counts_by_lang(train_ex))\n",
    "print('Dev pairs by language:', counts_by_lang(dev_ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1c579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99677d1f05e440e09f1ae4889473a71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build windows [train]:   0%|          | 0/461 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cea96e84124d54816c46fb4a05e85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encode windows [train]:   0%|          | 0/461 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cache: train_windows.pt and train_winemb.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32346216571d47d3b4b5e0f038a744d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build windows [dev]:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfc020657b34170becb818255208847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encode windows [dev]:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cache: dev_windows.pt and dev_winemb.pt\n",
      "Saved entity embedding cache: entity_embeds.pt n= 5785\n"
     ]
    }
   ],
   "source": [
    "# 4) Windowing + frozen embedding caches (document windows + entity strings)\n",
    "from typing import Callable\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "MIL_CACHE_DIR = WORK_DIR / 'mil_cache'\n",
    "MIL_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = 'xlm-roberta-base'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "encoder = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "encoder.eval()\n",
    "for p in encoder.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 13) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(13)\n",
    "\n",
    "\n",
    "def chunk_text_by_tokens(text: str, *, max_tokens: int = 256, stride: int = 128) -> List[str]:\n",
    "    text = (text or '').replace('\\n', ' ').strip()\n",
    "    if not text:\n",
    "        return ['']\n",
    "    enc = tokenizer(text, add_special_tokens=False, return_attention_mask=False, return_tensors=None)\n",
    "    ids = enc['input_ids']\n",
    "    if len(ids) <= max_tokens:\n",
    "        return [text]\n",
    "    windows: List[str] = []\n",
    "    start = 0\n",
    "    while start < len(ids):\n",
    "        end = min(len(ids), start + max_tokens)\n",
    "        chunk_ids = ids[start:end]\n",
    "        chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "        chunk_text = chunk_text.strip()\n",
    "        if chunk_text:\n",
    "            windows.append(chunk_text)\n",
    "        if end == len(ids):\n",
    "            break\n",
    "        start = max(0, end - stride)\n",
    "    return windows if windows else [text[:1000]]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_texts(texts: List[str], *, batch_size: int = 32, max_length: int = 256) -> torch.Tensor:\n",
    "    vecs: List[torch.Tensor] = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        tok = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        tok = {k: v.to(device) for k, v in tok.items()}\n",
    "        out = encoder(**tok).last_hidden_state\n",
    "        cls = out[:, 0, :].detach().cpu()\n",
    "        vecs.append(cls)\n",
    "    return torch.cat(vecs, dim=0)\n",
    "\n",
    "\n",
    "def build_doc_index(docs: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
    "    idx: Dict[str, Dict[str, Any]] = {}\n",
    "    for doc in docs:\n",
    "        doc_id = str(doc.get('document_id') or doc.get('doc_id') or doc.get('id') or '')\n",
    "        if not doc_id:\n",
    "            continue\n",
    "        idx[doc_id] = doc\n",
    "    return idx\n",
    "\n",
    "\n",
    "train_doc_by_id = build_doc_index(train_docs)\n",
    "dev_doc_by_id = build_doc_index(dev_docs)\n",
    "\n",
    "\n",
    "def precompute_doc_windows_and_embeds(\n",
    "    *,\n",
    "    split_name: str,\n",
    "    docs_by_id: Dict[str, Dict[str, Any]],\n",
    "    max_tokens: int = 256,\n",
    "    stride: int = 128,\n",
    "    max_length: int = 256,\n",
    "    recompute: bool = False,\n",
    ") -> Tuple[Dict[str, List[str]], Dict[str, torch.Tensor]]:\n",
    "    win_path = MIL_CACHE_DIR / f'{split_name}_windows.pt'\n",
    "    emb_path = MIL_CACHE_DIR / f'{split_name}_winemb.pt'\n",
    "    if (not recompute) and win_path.exists() and emb_path.exists():\n",
    "        print(f'Loading cached windows/embeddings for {split_name}...')\n",
    "        doc_windows = torch.load(win_path)\n",
    "        doc_embeds = torch.load(emb_path)\n",
    "        return doc_windows, doc_embeds\n",
    "\n",
    "    doc_windows: Dict[str, List[str]] = {}\n",
    "    doc_embeds: Dict[str, torch.Tensor] = {}\n",
    "    for doc_id, doc in tqdm(list(docs_by_id.items()), desc=f'Build windows [{split_name}]'):\n",
    "        text = str(doc.get('text') or '')\n",
    "        windows = chunk_text_by_tokens(text, max_tokens=max_tokens, stride=stride)\n",
    "        doc_windows[doc_id] = windows\n",
    "    for doc_id, windows in tqdm(list(doc_windows.items()), desc=f'Encode windows [{split_name}]'):\n",
    "        embeds = encode_texts(windows, batch_size=32, max_length=max_length)\n",
    "        doc_embeds[doc_id] = embeds  # [W, H] on CPU\n",
    "    torch.save(doc_windows, win_path)\n",
    "    torch.save(doc_embeds, emb_path)\n",
    "    print('Saved cache:', win_path.name, 'and', emb_path.name)\n",
    "    return doc_windows, doc_embeds\n",
    "\n",
    "\n",
    "DOC_MAX_TOKENS = 256\n",
    "DOC_STRIDE = 128\n",
    "WIN_MAX_LENGTH = 256\n",
    "RECOMPUTE_EMBEDS = False\n",
    "\n",
    "train_doc_windows, train_doc_embeds = precompute_doc_windows_and_embeds(\n",
    "    split_name='train',\n",
    "    docs_by_id=train_doc_by_id,\n",
    "    max_tokens=DOC_MAX_TOKENS,\n",
    "    stride=DOC_STRIDE,\n",
    "    max_length=WIN_MAX_LENGTH,\n",
    "    recompute=RECOMPUTE_EMBEDS,\n",
    ")\n",
    "dev_doc_windows, dev_doc_embeds = precompute_doc_windows_and_embeds(\n",
    "    split_name='dev',\n",
    "    docs_by_id=dev_doc_by_id,\n",
    "    max_tokens=DOC_MAX_TOKENS,\n",
    "    stride=DOC_STRIDE,\n",
    "    max_length=WIN_MAX_LENGTH,\n",
    "    recompute=RECOMPUTE_EMBEDS,\n",
    ")\n",
    "\n",
    "\n",
    "# Entity embedding cache (encode multiple mention variants)\n",
    "def build_entity_text(ex: PairExampleMIL) -> Tuple[str, str]:\n",
    "    # Using multiple variants helps robustness to OCR/newlines.\n",
    "    p_ms = [m.strip().replace('\\n', ' ') for m in (ex.pers_mentions or []) if isinstance(m, str) and m.strip()]\n",
    "    l_ms = [m.strip().replace('\\n', ' ') for m in (ex.loc_mentions or []) if isinstance(m, str) and m.strip()]\n",
    "    p = ' ; '.join(p_ms[:3]) if p_ms else (ex.pers_mention.strip() if ex.pers_mention else '')\n",
    "    l = ' ; '.join(l_ms[:3]) if l_ms else (ex.loc_mention.strip() if ex.loc_mention else '')\n",
    "    return f'Person: {p}', f'Location: {l}'\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def precompute_entity_embeds(examples: List[PairExampleMIL], *, max_length: int = 48) -> Dict[str, torch.Tensor]:\n",
    "    # key by entity id; store [H] on CPU\n",
    "    ent_texts: Dict[str, str] = {}\n",
    "    for ex in examples:\n",
    "        p_text, l_text = build_entity_text(ex)\n",
    "        if ex.pers_entity_id and ex.pers_entity_id not in ent_texts:\n",
    "            ent_texts[ex.pers_entity_id] = p_text\n",
    "        if ex.loc_entity_id and ex.loc_entity_id not in ent_texts:\n",
    "            ent_texts[ex.loc_entity_id] = l_text\n",
    "    ids = list(ent_texts.keys())\n",
    "    texts = [ent_texts[i] for i in ids]\n",
    "    vec = encode_texts(texts, batch_size=64, max_length=max_length)\n",
    "    return {k: vec[i] for i, k in enumerate(ids)}\n",
    "\n",
    "\n",
    "ent_cache_path = MIL_CACHE_DIR / 'entity_embeds.pt'\n",
    "if ent_cache_path.exists() and (not RECOMPUTE_EMBEDS):\n",
    "    entity_embeds = torch.load(ent_cache_path)\n",
    "    print('Loaded entity embedding cache:', ent_cache_path.name, 'n=', len(entity_embeds))\n",
    "else:\n",
    "    entity_embeds = precompute_entity_embeds(train_ex + dev_ex, max_length=48)\n",
    "    torch.save(entity_embeds, ent_cache_path)\n",
    "    print('Saved entity embedding cache:', ent_cache_path.name, 'n=', len(entity_embeds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546df0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e80f76691c442b8a54e6c0f8f40a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build pair instances:   0%|          | 0/6170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e782c1cd31491ea75af7e6a636f4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build pair instances:   0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIL train instances: 6170 dev instances: 151\n",
      "Train batches: 97 Dev batches: 3\n"
     ]
    }
   ],
   "source": [
    "# 5) Build MIL instances (candidate windows per pair) + DataLoaders\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from typing import NamedTuple\n",
    "import re\n",
    "\n",
    "\n",
    "class MILInstance(NamedTuple):\n",
    "    document_id: str\n",
    "    pair_index: int\n",
    "    pers_entity_id: str\n",
    "    loc_entity_id: str\n",
    "    cand_win_idx: List[int]\n",
    "    y_at: int\n",
    "    y_isat: int\n",
    "\n",
    "\n",
    "_ws_re = re.compile(r\"\\s+\")\n",
    "_nonword_re = re.compile(r\"[^\\w\\s]\")\n",
    "\n",
    "def _norm_for_match(s: str) -> str:\n",
    "    # Robust to OCR/newlines/punctuation differences.\n",
    "    s = (s or '').replace('\\n', ' ').casefold()\n",
    "    s = _ws_re.sub(' ', s).strip()\n",
    "    s = _nonword_re.sub(' ', s)\n",
    "    s = _ws_re.sub(' ', s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def _norm_mentions(ms: List[str]) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    seen = set()\n",
    "    for m in ms or []:\n",
    "        if not isinstance(m, str):\n",
    "            continue\n",
    "        nm = _norm_for_match(m)\n",
    "        if not nm or nm in seen:\n",
    "            continue\n",
    "        seen.add(nm)\n",
    "        out.append(nm)\n",
    "    # Prefer longer mentions first (more specific)\n",
    "    out.sort(key=len, reverse=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _evenly_spaced_indices(n: int, k: int) -> List[int]:\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    if n <= k:\n",
    "        return list(range(n))\n",
    "    # include start, middle, end-ish\n",
    "    xs = np.linspace(0, n - 1, num=k)\n",
    "    idx = sorted({int(round(x)) for x in xs})\n",
    "    if len(idx) < k:\n",
    "        # fill deterministically\n",
    "        for i in range(n):\n",
    "            if i not in idx:\n",
    "                idx.append(i)\n",
    "            if len(idx) == k:\n",
    "                break\n",
    "        idx.sort()\n",
    "    return idx[:k]\n",
    "\n",
    "\n",
    "def find_candidate_windows(\n",
    "    windows: List[str],\n",
    "    pers_mentions: List[str],\n",
    "    loc_mentions: List[str],\n",
    "    *,\n",
    "    max_keep: int = 32,\n",
    ") -> List[int]:\n",
    "    # Score each window by lexical matches against ANY mention surface form.\n",
    "    p_ms = _norm_mentions(pers_mentions)\n",
    "    l_ms = _norm_mentions(loc_mentions)\n",
    "\n",
    "    scores: List[Tuple[int, int]] = []  # (score, idx)\n",
    "    for i, w in enumerate(windows):\n",
    "        wl = _norm_for_match(w)\n",
    "        sp = 0\n",
    "        sl = 0\n",
    "        for m in p_ms[:10]:\n",
    "            if m and m in wl:\n",
    "                sp = 1\n",
    "                break\n",
    "        for m in l_ms[:10]:\n",
    "            if m and m in wl:\n",
    "                sl = 1\n",
    "                break\n",
    "        s = 0\n",
    "        if sp and sl:\n",
    "            s = 3\n",
    "        elif sp or sl:\n",
    "            s = 1\n",
    "        if s > 0:\n",
    "            scores.append((s, i))\n",
    "\n",
    "    if not scores:\n",
    "        # Fallback: avoid always selecting the beginning of the document.\n",
    "        return _evenly_spaced_indices(len(windows), max_keep)\n",
    "\n",
    "    # Prefer windows that contain BOTH entities, then partial matches.\n",
    "    scores.sort(key=lambda x: (x[0], -x[1]), reverse=True)\n",
    "    top = [i for _, i in scores[:max_keep]]\n",
    "    top = sorted(set(top))\n",
    "    return top\n",
    "\n",
    "\n",
    "def build_instances(\n",
    "    examples: List[PairExampleMIL],\n",
    "    doc_windows: Dict[str, List[str]],\n",
    ") -> List[MILInstance]:\n",
    "    out: List[MILInstance] = []\n",
    "    for ex in tqdm(examples, desc='Build pair instances'):\n",
    "        wins = doc_windows.get(ex.document_id)\n",
    "        if not wins:\n",
    "            continue\n",
    "        cand = find_candidate_windows(wins, ex.pers_mentions, ex.loc_mentions)\n",
    "        if ex.at not in AT2ID or ex.isAt not in ISAT2ID:\n",
    "            continue\n",
    "        out.append(MILInstance(\n",
    "            document_id=ex.document_id,\n",
    "            pair_index=ex.pair_index,\n",
    "            pers_entity_id=ex.pers_entity_id,\n",
    "            loc_entity_id=ex.loc_entity_id,\n",
    "            cand_win_idx=cand,\n",
    "            y_at=AT2ID[ex.at],\n",
    "            y_isat=ISAT2ID[ex.isAt],\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "\n",
    "train_inst = build_instances(train_ex, train_doc_windows)\n",
    "dev_inst = build_instances(dev_ex, dev_doc_windows)\n",
    "print('MIL train instances:', len(train_inst), 'dev instances:', len(dev_inst))\n",
    "\n",
    "\n",
    "class MILDataset(Dataset):\n",
    "    def __init__(self, instances: List[MILInstance]):\n",
    "        self.instances = instances\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, i: int) -> MILInstance:\n",
    "        return self.instances[i]\n",
    "\n",
    "\n",
    "def mil_collate(batch: List[MILInstance]) -> Dict[str, Any]:\n",
    "    # Build padded window-embedding tensors per example\n",
    "    doc_ids = [b.document_id for b in batch]\n",
    "    p_ids = [b.pers_entity_id for b in batch]\n",
    "    l_ids = [b.loc_entity_id for b in batch]\n",
    "    y_at = torch.tensor([b.y_at for b in batch], dtype=torch.long)\n",
    "    y_is = torch.tensor([b.y_isat for b in batch], dtype=torch.long)\n",
    "\n",
    "    # Window embeddings\n",
    "    embeds_list: List[torch.Tensor] = []\n",
    "    max_w = 1\n",
    "    H = int(encoder.config.hidden_size)\n",
    "    for b in batch:\n",
    "        if b.document_id in train_doc_embeds:\n",
    "            e = train_doc_embeds[b.document_id]\n",
    "        elif b.document_id in dev_doc_embeds:\n",
    "            e = dev_doc_embeds[b.document_id]\n",
    "        else:\n",
    "            e = torch.zeros((1, H), dtype=torch.float32)\n",
    "        embeds_list.append(e)\n",
    "        max_w = max(max_w, e.shape[0])\n",
    "\n",
    "    win_emb = torch.zeros((len(batch), max_w, H), dtype=torch.float32)\n",
    "    win_valid = torch.zeros((len(batch), max_w), dtype=torch.bool)\n",
    "    win_cand = torch.zeros((len(batch), max_w), dtype=torch.bool)\n",
    "    for i, (b, e) in enumerate(zip(batch, embeds_list)):\n",
    "        w = e.shape[0]\n",
    "        win_emb[i, :w] = e\n",
    "        win_valid[i, :w] = True\n",
    "        for j in b.cand_win_idx:\n",
    "            if j < w:\n",
    "                win_cand[i, j] = True\n",
    "        if not win_cand[i, :w].any():\n",
    "            win_cand[i, :w] = True\n",
    "\n",
    "    # Entity embeddings\n",
    "    zero = torch.zeros((H,), dtype=torch.float32)\n",
    "    p_emb = torch.stack([entity_embeds.get(pid, zero) for pid in p_ids], dim=0).float()\n",
    "    l_emb = torch.stack([entity_embeds.get(lid, zero) for lid in l_ids], dim=0).float()\n",
    "    return {\n",
    "        'doc_ids': doc_ids,\n",
    "        'pair_index': [b.pair_index for b in batch],\n",
    "        'p_emb': p_emb,\n",
    "        'l_emb': l_emb,\n",
    "        'win_emb': win_emb,\n",
    "        'win_valid': win_valid,\n",
    "        'win_cand': win_cand,\n",
    "        'y_at': y_at,\n",
    "        'y_isAt': y_is,\n",
    "    }\n",
    "\n",
    "\n",
    "# Weighted sampling to fight label imbalance (balance joint (at,isAt) combos)\n",
    "combo_counts = Counter((b.y_at, b.y_isat) for b in train_inst)\n",
    "weights = np.array([1.0 / combo_counts[(b.y_at, b.y_isat)] for b in train_inst], dtype=np.float64)\n",
    "weights = weights / weights.mean()\n",
    "sampler = WeightedRandomSampler(weights=torch.tensor(weights, dtype=torch.double), num_samples=len(train_inst), replacement=True)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(MILDataset(train_inst), batch_size=BATCH_SIZE, sampler=sampler, shuffle=False, collate_fn=mil_collate)\n",
    "dev_loader = DataLoader(MILDataset(dev_inst), batch_size=BATCH_SIZE, shuffle=False, collate_fn=mil_collate)\n",
    "print('Train batches:', len(train_loader), 'Dev batches:', len(dev_loader))\n",
    "print('Train combo counts:', dict(sorted(combo_counts.items())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1d639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights at: [0.6638366 1.0119148 1.3242487]\n",
      "Class weights isAt: [0.5196881 1.480312 ]\n",
      "MIL model params: 6.494213 M\n"
     ]
    }
   ],
   "source": [
    "# 6) MIL model: attention over windows conditioned on (person, location)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class EvidenceMIL(nn.Module):\n",
    "    def __init__(self, hidden_size: int, *, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.hidden = hidden_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Pair -> query\n",
    "        self.pair_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 4, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "\n",
    "        # Attention projection for windows\n",
    "        self.win_proj = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.attn_temp = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "        # Shared trunk before heads\n",
    "        # features: p,l,attn_pool,max_pool,|p-l|,p*l\n",
    "        feat_dim = hidden_size * 6\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Linear(feat_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.head_at = nn.Linear(hidden_size, 3)\n",
    "        self.head_isat = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        p_emb: torch.Tensor,      # [B,H]\n",
    "        l_emb: torch.Tensor,      # [B,H]\n",
    "        win_emb: torch.Tensor,    # [B,W,H]\n",
    "        win_valid: torch.Tensor,  # [B,W] bool\n",
    "        win_cand: torch.Tensor,   # [B,W] bool\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        B, W, H = win_emb.shape\n",
    "        p = self.dropout(p_emb)\n",
    "        l = self.dropout(l_emb)\n",
    "\n",
    "        # query uses interactions but not pooled evidence\n",
    "        x = torch.cat([p, l, torch.abs(p - l), p * l], dim=-1)\n",
    "        q = self.pair_mlp(x)  # [B,H]\n",
    "\n",
    "        # window scores: (Wproj(v_w)) dot q\n",
    "        v = self.win_proj(win_emb)  # [B,W,H]\n",
    "        scores = torch.einsum('bwh,bh->bw', v, q)\n",
    "\n",
    "        # Mask out invalid/padded windows and non-candidate windows\n",
    "        mask = win_valid & win_cand\n",
    "        scores = scores / (torch.clamp(self.attn_temp, min=0.2, max=5.0))\n",
    "        scores = scores.masked_fill(~mask, -1e9)\n",
    "\n",
    "        attn = torch.softmax(scores, dim=-1)  # [B,W]\n",
    "        v_attn = torch.einsum('bw,bwh->bh', attn, win_emb)\n",
    "\n",
    "        # Max pool over candidate windows (complementary to attention)\n",
    "        win_emb_masked = win_emb.masked_fill(~mask.unsqueeze(-1), float('-inf'))\n",
    "        v_max = win_emb_masked.max(dim=1).values\n",
    "        v_max = torch.nan_to_num(v_max, nan=0.0, neginf=0.0, posinf=0.0)\n",
    "\n",
    "        feats = torch.cat([p, l, v_attn, v_max, torch.abs(p - l), p * l], dim=-1)\n",
    "        h = self.trunk(feats)\n",
    "        return {\n",
    "            'logits_at': self.head_at(h),\n",
    "            'logits_isAt': self.head_isat(h),\n",
    "            'attn': attn,\n",
    "        }\n",
    "\n",
    "\n",
    "def inv_sqrt_class_weights(y: np.ndarray, num_classes: int) -> torch.Tensor:\n",
    "    counts = np.bincount(y, minlength=num_classes).astype(np.float32)\n",
    "    w = 1.0 / np.sqrt(np.maximum(counts, 1.0))\n",
    "    w = w * (num_classes / w.sum())\n",
    "    return torch.tensor(w, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Class weights (computed from training labels)\n",
    "y_at_train = np.array([b.y_at for b in train_inst], dtype=np.int64)\n",
    "y_is_train = np.array([b.y_isat for b in train_inst], dtype=np.int64)\n",
    "w_at = inv_sqrt_class_weights(y_at_train, 3).to(device)\n",
    "w_is = inv_sqrt_class_weights(y_is_train, 2).to(device)\n",
    "print('Class weights at:', w_at.detach().cpu().numpy())\n",
    "print('Class weights isAt:', w_is.detach().cpu().numpy())\n",
    "\n",
    "mil_model = EvidenceMIL(hidden_size=int(encoder.config.hidden_size), dropout=0.25).to(device)\n",
    "print('MIL model params:', sum(p.numel() for p in mil_model.parameters())/1e6, 'M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2bccc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4377102053409fafce5c87363d8908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/30:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'train_loss': 2.229541878110355, 'val_loss': 1.7157322963078816, 'acc_at': 0.4503311258278146, 'acc_isAt': 0.8807947019867549, 'macro_recall_at': 0.3333333333333333, 'macro_recall_isAt': 0.5, 'avg_macro_recall': 0.41666666666666663}\n",
      "Saved best -> /content/mil_cache/best_mil_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8020eb6d07845c2b5e8644f44f6669f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/30:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2, 'train_loss': 1.6378914437343164, 'val_loss': 1.6631971995035808, 'acc_at': 0.4503311258278146, 'acc_isAt': 0.8807947019867549, 'macro_recall_at': 0.3333333333333333, 'macro_recall_isAt': 0.5, 'avg_macro_recall': 0.41666666666666663}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2b18537c764518a91b3cd4130567cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/30:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 3, 'train_loss': 1.6447333380119087, 'val_loss': 1.6629846890767415, 'acc_at': 0.4503311258278146, 'acc_isAt': 0.8807947019867549, 'macro_recall_at': 0.3333333333333333, 'macro_recall_isAt': 0.5, 'avg_macro_recall': 0.41666666666666663}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cad604bb5d41789c9c8c8ae32f2e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/30:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'train_loss': 1.6260318866710073, 'val_loss': 1.6739999453226726, 'acc_at': 0.4503311258278146, 'acc_isAt': 0.8807947019867549, 'macro_recall_at': 0.3333333333333333, 'macro_recall_isAt': 0.5, 'avg_macro_recall': 0.41666666666666663}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283f53990d1d4586942ed0b95df8563c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/30:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 5, 'train_loss': 1.6386383120546635, 'val_loss': 1.6816920439402263, 'acc_at': 0.4503311258278146, 'acc_isAt': 0.8807947019867549, 'macro_recall_at': 0.3333333333333333, 'macro_recall_isAt': 0.5, 'avg_macro_recall': 0.41666666666666663}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77035756aba2419a9c92bed3828100be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/30:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 6, 'train_loss': 1.6281058284425245, 'val_loss': 1.6890898545583088, 'acc_at': 0.4503311258278146, 'acc_isAt': 0.8807947019867549, 'macro_recall_at': 0.3333333333333333, 'macro_recall_isAt': 0.5, 'avg_macro_recall': 0.41666666666666663}\n",
      "Early stopping: no improvement for 5 epochs\n",
      "Best: {'avg_macro_recall': 0.41666666666666663, 'epoch': 1}\n",
      "Loaded best checkpoint\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cbed7aea-73fa-4708-94d5-086f4bbc6837\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>acc_at</th>\n",
       "      <th>acc_isAt</th>\n",
       "      <th>macro_recall_at</th>\n",
       "      <th>macro_recall_isAt</th>\n",
       "      <th>avg_macro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.229542</td>\n",
       "      <td>1.715732</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.637891</td>\n",
       "      <td>1.663197</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.644733</td>\n",
       "      <td>1.662985</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.626032</td>\n",
       "      <td>1.674000</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.638638</td>\n",
       "      <td>1.681692</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.628106</td>\n",
       "      <td>1.689090</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbed7aea-73fa-4708-94d5-086f4bbc6837')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cbed7aea-73fa-4708-94d5-086f4bbc6837 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cbed7aea-73fa-4708-94d5-086f4bbc6837');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   epoch  train_loss  val_loss    acc_at  acc_isAt  macro_recall_at  \\\n",
       "0      1    2.229542  1.715732  0.450331  0.880795         0.333333   \n",
       "1      2    1.637891  1.663197  0.450331  0.880795         0.333333   \n",
       "2      3    1.644733  1.662985  0.450331  0.880795         0.333333   \n",
       "3      4    1.626032  1.674000  0.450331  0.880795         0.333333   \n",
       "4      5    1.638638  1.681692  0.450331  0.880795         0.333333   \n",
       "5      6    1.628106  1.689090  0.450331  0.880795         0.333333   \n",
       "\n",
       "   macro_recall_isAt  avg_macro_recall  \n",
       "0                0.5          0.416667  \n",
       "1                0.5          0.416667  \n",
       "2                0.5          0.416667  \n",
       "3                0.5          0.416667  \n",
       "4                0.5          0.416667  \n",
       "5                0.5          0.416667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7) Training + evaluation (macro recall) + early stopping\n",
    "def macro_recall(y_true: np.ndarray, y_pred: np.ndarray, labels: List[int]) -> float:\n",
    "    return float(recall_score(y_true, y_pred, average='macro', labels=labels, zero_division=0))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mil(model: EvidenceMIL, loader: DataLoader) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    ys_at, ps_at = [], []\n",
    "    ys_is, ps_is = [], []\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for batch in loader:\n",
    "        p = batch['p_emb'].to(device)\n",
    "        l = batch['l_emb'].to(device)\n",
    "        win_emb = batch['win_emb'].to(device)\n",
    "        win_valid = batch['win_valid'].to(device)\n",
    "        win_cand = batch['win_cand'].to(device)\n",
    "        y_at = batch['y_at'].to(device)\n",
    "        y_is = batch['y_isAt'].to(device)\n",
    "        out = model(p, l, win_emb, win_valid, win_cand)\n",
    "        loss_at = F.cross_entropy(out['logits_at'], y_at, weight=w_at)\n",
    "        loss_is = F.cross_entropy(out['logits_isAt'], y_is, weight=w_is)\n",
    "        loss = loss_at + loss_is\n",
    "        total_loss += float(loss.item())\n",
    "        n_batches += 1\n",
    "        pa = out['logits_at'].argmax(dim=-1).detach().cpu().numpy()\n",
    "        pi = out['logits_isAt'].argmax(dim=-1).detach().cpu().numpy()\n",
    "        ys_at.append(y_at.detach().cpu().numpy())\n",
    "        ps_at.append(pa)\n",
    "        ys_is.append(y_is.detach().cpu().numpy())\n",
    "        ps_is.append(pi)\n",
    "    y_at_all = np.concatenate(ys_at)\n",
    "    p_at_all = np.concatenate(ps_at)\n",
    "    y_is_all = np.concatenate(ys_is)\n",
    "    p_is_all = np.concatenate(ps_is)\n",
    "    mr_at = macro_recall(y_at_all, p_at_all, labels=list(range(3)))\n",
    "    mr_is = macro_recall(y_is_all, p_is_all, labels=list(range(2)))\n",
    "    acc_at = float(accuracy_score(y_at_all, p_at_all))\n",
    "    acc_is = float(accuracy_score(y_is_all, p_is_all))\n",
    "    return {\n",
    "        'val_loss': total_loss / max(1, n_batches),\n",
    "        'acc_at': acc_at,\n",
    "        'acc_isAt': acc_is,\n",
    "        'macro_recall_at': mr_at,\n",
    "        'macro_recall_isAt': mr_is,\n",
    "        'avg_macro_recall': 0.5 * (mr_at + mr_is),\n",
    "    }\n",
    "\n",
    "LR = 2e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 30\n",
    "PATIENCE = 5\n",
    "optimizer = torch.optim.AdamW(mil_model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "best = {'avg_macro_recall': -1.0, 'epoch': -1}\n",
    "best_path = MIL_CACHE_DIR / 'best_mil_model.pt'\n",
    "bad_epochs = 0\n",
    "history: List[Dict[str, float]] = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    mil_model.train()\n",
    "    total = 0.0\n",
    "    n = 0\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{EPOCHS}')\n",
    "    for batch in pbar:\n",
    "        p = batch['p_emb'].to(device)\n",
    "        l = batch['l_emb'].to(device)\n",
    "        win_emb = batch['win_emb'].to(device)\n",
    "        win_valid = batch['win_valid'].to(device)\n",
    "        win_cand = batch['win_cand'].to(device)\n",
    "        y_at = batch['y_at'].to(device)\n",
    "        y_is = batch['y_isAt'].to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        out = mil_model(p, l, win_emb, win_valid, win_cand)\n",
    "        loss_at = F.cross_entropy(out['logits_at'], y_at, weight=w_at)\n",
    "        loss_is = F.cross_entropy(out['logits_isAt'], y_is, weight=w_is)\n",
    "        loss = loss_at + loss_is\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(mil_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total += float(loss.item())\n",
    "        n += 1\n",
    "        if n % 10 == 0:\n",
    "            pbar.set_postfix(train_loss=total / max(1, n))\n",
    "    metrics = evaluate_mil(mil_model, dev_loader)\n",
    "    row = {'epoch': epoch, 'train_loss': total / max(1, n), **metrics}\n",
    "    history.append(row)\n",
    "    print(row)\n",
    "    if metrics['avg_macro_recall'] > best['avg_macro_recall']:\n",
    "        best = {'avg_macro_recall': metrics['avg_macro_recall'], 'epoch': epoch}\n",
    "        torch.save({'model': mil_model.state_dict()}, best_path)\n",
    "        print('Saved best ->', best_path)\n",
    "        bad_epochs = 0\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "        if bad_epochs >= PATIENCE:\n",
    "            print(f'Early stopping: no improvement for {PATIENCE} epochs')\n",
    "            break\n",
    "\n",
    "print('Best:', best)\n",
    "if best_path.exists():\n",
    "    mil_model.load_state_dict(torch.load(best_path, map_location=device)['model'])\n",
    "    print('Loaded best checkpoint')\n",
    "\n",
    "df = pd.DataFrame(history)\n",
    "if len(df):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789b8ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741c14acfa09421babf13bad43e80c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for pairs: 151\n",
      "Wrote: /content/en_dev_predictions_mil.jsonl\n"
     ]
    }
   ],
   "source": [
    "# 8) Predict + export back to HIPE JSONL\n",
    "@torch.no_grad()\n",
    "def predict_mil(model: EvidenceMIL, loader: DataLoader) -> Dict[Tuple[str, int], Tuple[str, str]]:\n",
    "    model.eval()\n",
    "    out_map: Dict[Tuple[str, int], Tuple[str, str]] = {}\n",
    "    for batch in tqdm(loader, desc='Predict'):\n",
    "        p = batch['p_emb'].to(device)\n",
    "        l = batch['l_emb'].to(device)\n",
    "        win_emb = batch['win_emb'].to(device)\n",
    "        win_valid = batch['win_valid'].to(device)\n",
    "        win_cand = batch['win_cand'].to(device)\n",
    "        out = model(p, l, win_emb, win_valid, win_cand)\n",
    "        pa = out['logits_at'].argmax(dim=-1).detach().cpu().numpy()\n",
    "        pi = out['logits_isAt'].argmax(dim=-1).detach().cpu().numpy()\n",
    "        for doc_id, pair_idx, a, i_ in zip(batch['doc_ids'], batch['pair_index'], pa, pi):\n",
    "            out_map[(str(doc_id), int(pair_idx))] = (ID2AT[int(a)], ID2ISAT[int(i_)])\n",
    "    return out_map\n",
    "\n",
    "pred_map = predict_mil(mil_model, dev_loader)\n",
    "print('Predictions for pairs:', len(pred_map))\n",
    "\n",
    "def write_predictions_jsonl(\n",
    "    docs: List[Dict[str, Any]],\n",
    "    pred_by_pair: Dict[Tuple[str, int], Tuple[str, str]],\n",
    "    out_path: Path,\n",
    ") -> None:\n",
    "    with out_path.open('w', encoding='utf-8') as f:\n",
    "        for doc in docs:\n",
    "            doc_id = str(doc.get('document_id') or doc.get('doc_id') or doc.get('id') or '')\n",
    "            new_doc = dict(doc)\n",
    "            new_pairs = []\n",
    "            for idx, pair in enumerate(doc.get('sampled_pairs', [])):\n",
    "                new_pair = dict(pair)\n",
    "                at_pred, isat_pred = pred_by_pair.get((doc_id, idx), ('FALSE', 'FALSE'))\n",
    "                new_pair['at'] = at_pred\n",
    "                new_pair['isAt'] = isat_pred\n",
    "                new_pairs.append(new_pair)\n",
    "            new_doc['sampled_pairs'] = new_pairs\n",
    "            f.write(json.dumps(new_doc, ensure_ascii=False) + '\\n')\n",
    "\n",
    "dev_lang = DEV_LANG\n",
    "out_path = Path.cwd() / f'{dev_lang}_dev_predictions_mil.jsonl'\n",
    "write_predictions_jsonl(dev_docs, pred_map, out_path)\n",
    "print('Wrote:', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89fd0e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded docs: 17 expected: 17\n",
      "doc_id: sn84026272-1800-12-10-a-i0004 | pairs: 4\n",
      "   0 FALSE FALSE\n",
      "   1 FALSE FALSE\n",
      "   2 FALSE FALSE\n",
      "doc_id: sn88085488-1910-09-23-a-i0001 | pairs: 10\n",
      "   0 FALSE FALSE\n",
      "   1 FALSE FALSE\n",
      "   2 FALSE FALSE\n",
      "doc_id: sn85042404-1880-12-21-a-i0002 | pairs: 1\n",
      "   0 FALSE FALSE\n",
      "doc_id: sn82014385-1810-04-04-a-i0003 | pairs: 16\n",
      "   0 FALSE FALSE\n",
      "   1 FALSE FALSE\n",
      "   2 FALSE FALSE\n",
      "doc_id: sn83026170-1820-01-15-a-i0002 | pairs: 6\n",
      "   0 FALSE FALSE\n",
      "   1 FALSE FALSE\n",
      "   2 FALSE FALSE\n",
      "Total pairs in file (first 5 docs counted separately): 37\n",
      "Pairs missing at/isAt: 0\n"
     ]
    }
   ],
   "source": [
    "# 9) Sanity checks on exported JSONL\n",
    "reloaded = read_jsonl(out_path)\n",
    "print('Reloaded docs:', len(reloaded), 'expected:', len(dev_docs))\n",
    "assert len(reloaded) == len(dev_docs)\n",
    "n_pairs = 0\n",
    "for d in reloaded[:5]:\n",
    "    doc_id = d.get('document_id')\n",
    "    pairs = d.get('sampled_pairs', [])\n",
    "    print('doc_id:', doc_id, '| pairs:', len(pairs))\n",
    "    for j, p in enumerate(pairs[:3]):\n",
    "        print('  ', j, p.get('at'), p.get('isAt'))\n",
    "    n_pairs += len(pairs)\n",
    "print('Total pairs in file (first 5 docs counted separately):', n_pairs)\n",
    "\n",
    "# Validate that every sampled_pairs entry has at/isAt strings\n",
    "missing = 0\n",
    "for d in reloaded:\n",
    "    for p in d.get('sampled_pairs', []):\n",
    "        if ('at' not in p) or ('isAt' not in p):\n",
    "            missing += 1\n",
    "print('Pairs missing at/isAt:', missing)\n",
    "assert missing == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
